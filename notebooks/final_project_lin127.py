# -*- coding: utf-8 -*-
"""final_project_LIN127.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w4aAMxDhtOYo3HMQvghN2c8b-S6IfsT3
"""

#check which files are in this directory since we will add our zip file here
import os
print(os.listdir("/content"))

#downloaded all transcripts from SCOTUS website:
#unzip them and place them into the OralArguments section
!unzip OralArguments.zip -d OralArguments

#find all utterences of John G Roberts: appointed 2005, 50 at time....Ruth Ginsberg served with him 2005-2020 at death: at 72 she started working with him
#only look at utterences from year 2007

#used LLM for this section:

import os
import re

# directory of where we want to look at justice: Roberts
root_dir = 'OralArguments/OralArguments'
target_justice = 'ROBE'

#year we are looking at alone
target_year = '2007'

# empty list needed to input all his utterences into
robe_utterances = []

# iterating through the directories and subdirectories within them
for root, dirs, files in os.walk(root_dir):
    # check curr directory and see if it matches the year (2007) we are looking at
    if target_year in root:
        # iterate through the files in this year's directory
        for file in files:
            # double check that these files in this year have the .cha ext
            if file.endswith('.cha'):
                #want to read the file
                with open(os.path.join(root, file), 'r', encoding='utf-8') as f:
                    # read
                    contents = f.read()
                    # split the file into lines that we can go through in order to get the utterences
                    lines = contents.split('\n')
                    # Iterate through the lines
                    for line in lines:
                        # check where line starts with utterence of ROBERTS
                        if line.startswith('*' + target_justice + ':'):
                            # extract that utterence and remove any extra characters or punctuation that way we can tag them later
                            robe_utterance = re.sub(r'[^a-zA-Z\s]', '', line.replace('*' + target_justice + ':', '').strip()).lower()
                            robe_utterances.append(robe_utterance)

# print list of all Robert's utterences
#used LLM for this section:
for robe_utterance in robe_utterances:
    print(robe_utterance)

#same approach for utterenes year 2007 for Ginsberg

#used LLM for this section:

import os
import re

# Define the root # directory of where we want to look at justice: Ginsberg
root_dir = 'OralArguments/OralArguments'
target_justice = 'GINS'

#year we are looking at alone
target_year = '2007'

# empty list needed to input all her utterences into
gins_utterances = []

# iterating through the directories and subdirectories within them
for root, dirs, files in os.walk(root_dir):
    # check curr directory and see if it matches the year (2007) we are looking at
    if target_year in root:
        # iterate through the files in this year's directory
        for file in files:
            # double check that these files in this year have the .cha ext
            if file.endswith('.cha'):
                #want to read the file
                with open(os.path.join(root, file), 'r', encoding='utf-8') as f:
                    # read
                    contents = f.read()
                    # split the file into lines that we can go through in order to get the utterences
                    lines = contents.split('\n')
                    # Iterate through the lines
                    for line in lines:
                        # check where line starts with utterence of GINSBERG
                        if line.startswith('*' + target_justice + ':'):
                            # extract that utterence and remove any extra characters or punctuation that way we can tag them later
                            gins_utterance = re.sub(r'[^a-zA-Z\s]', '', line.replace('*' + target_justice + ':', '').strip()).lower()
                            gins_utterances.append(gins_utterance)

# print the list of all Ginsberg's utterances
#used LLM for this section:
for gins_utterance in gins_utterances:
    print(gins_utterance)

#want to find the top ten 30 most frequent owrds ginsberg uttered
#use Counter to count these from the list we made earlier
from collections import Counter
#change list into a one string
#use "join" to concatenate utterences from GINS to string
gins_utterance_string = ' '.join(gins_utterances)
#now that we have a single string we want to split it into "words"
gins_words = gins_utterance_string.split()
#use Counter again to count number of frequency for all her words
word_counts = Counter(gins_words)
#retrieve the most common 30 using approach hw 1
gins_most_common = (word_counts.most_common(30))
print(gins_most_common)

#get robert's utterences into single string and split into words, count frequency and output the top 30
robe_utterance_string = ' '.join(robe_utterances)
robe_words = robe_utterance_string.split()
word_counts = Counter(robe_words)
robe_most_common = (word_counts.most_common(30))
print(robe_most_common)

#find total num of words GINS said to compare with ROBE
len(gins_words)

len(robe_words)

#create a visual of the top 30 words to see how they differ between the two justices

#Robert's plot
#library to plt
import matplotlib.pyplot as plt
#create a function labeling the data, title, and x and y lines
def create_line_plot(data = "robe_most_common", title = "Robert's Top 30 Words", xlabel = 'words', ylabel= 'Amount'):
  #unzip the amount anf word for the most common 30 words for robe bc its a tuple with two values for each word: amount and word itself
    word, amount = zip(*robe_most_common)

    #plot with word on x and amount on y and add a circle for each point to make it easier to read
    plt.plot(word, amount, marker='o')
    #labeling
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    #asked LLM to help look at words since they were overlapping, said to rotate it so it's vertical
    plt.xticks(rotation=90)
    #show the plot and call the function
    plt.show()
create_line_plot()

#Ginsberg's Plot

def create_line_plot(data = "gins_most_common", title = "Ginsberg's Top 30 Words", xlabel = 'words', ylabel= 'Amount'):
    word, amount = zip(*gins_most_common)
    plt.plot(word, amount, marker='o')
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    #asked LLM to help look at words since they were overlapping, said to rotate it so it's vertical
    plt.xticks(rotation=90)
    plt.show()
    #show the plot and call the function
create_line_plot()

import nltk
nltk.download('averaged_perceptron_tagger_eng')
nltk.download('universal_tagset')
nltk.download('punkt_tab')

#for loop to go through the tuple for GINS most common words
#look at hw 3 for reference
for label, amount in gins_most_common:
    tokens = nltk.word_tokenize(label)
    my_tagged_text = nltk.pos_tag(tokens, tagset='universal')
    for label, tag in my_tagged_text:
      #print the label for POS and the word it corresponds to
      print(label, tag)

##for loop to go through the tuple for ROBE most common words
for label, amount in robe_most_common:
    tokens = nltk.word_tokenize(label)
    my_tagged_text = nltk.pos_tag(tokens, tagset='universal')
    for label, tag in my_tagged_text:
    #print the label for POS and the word it corresponds to
      print(label, tag)

#use fasttext from hw 3 approach
!pip install fasttext==0.9.1

#use data from the .cha files from year 2007: want to look at GINS and ROBE as well as other conservative and liberal judges
#alito: conservative, alito: conservative
data = [
    ("__label__conservative", "That's not what we're arguing."),
    ("__label__conservative", "It just reflects the fact that certain businesses , illegal businesses like gambling operations , like drug dealing , frequently generate large amounts of cash and they need to launder that cash in order to survive and to prosper."),
    ("__label__conservative", "They're not going to grow."),
    ("__label__conservative", "I don't think that doing a robbery in the alley would be a financial transaction (.) would be designing a financial transaction to conceal the unlawful nature and source of the proceeds."),
    ("__label__conservative", "I was going to try to say to Justice Souter's question before that if you have concerns that these kind of expense payments should not be treated as promotional money laundering , the way to address those is not by adopting a profit construction of proceeds , because that would do tremendous violence to the statute in other ways."),
    ("__label__conservative", "Those are people who are hiding money for criminals as a matter of their business."),
    ("__label__conservative", "I might like to keep my money in the cookie jar and it's perfectly legitimate money , Your Honor because I don't want when someone comes into my house for them to steal the cash."),
    ("__label__conservative", "For instance , just a drug dealer accepts payment for the drugs."),
    ("__label__conservative", "So someone who simply paid off whoever it is that ships in , you know , a ton of heroin , you'd say is not guilty then."),
    ("__label__conservative", "Well , how do they know even what the fiscal year of these enterprises is."),
    ("__label__conservative", "My point is the profits may not come in immediately , even though the underlying activity is exactly the same."),
    ("__label__conservative", "Thats not the states fault."),
    ("__label__conservative", "What is the relevance of strikes of black lawyers that you don't argue were based on race."),
    ("__label__conservative", "Then what is the relevance of the fact that the black lawyers were peremptorily challenged."),
    ("__label__conservative", "And there's a death verdict on Friday."),
    ("__label__conservative", "Let's take the example of an international drug ring that has assets in a foreign country."),
    ("__label__conservative", "It seems to me that what Kentucky is trying to do is to , at least in part , provide make-whole benefits for a police officer who becomes disabled below a certain age."),
    ("__label__conservative", "But if do you that , aren't you going to be undercompensating the younger person who gets disabled and overcompensating the people over a certain age."),
    ("__label__conservative", "That would be a good argument if the sole basis for retirement under your system was years of service , but it's not just years of service , isn't that right."),
    ("__label__conservative", "In the case of a profitable illegal enterprise , all of the same problems exist."),
    ("__label__conservative", "There are drug businesses and all sorts of other predicates."),
    ("__label__conservative", "They may have lost a lot of things because they were raided by the government , destroyed the factory , killed the plants."),
    ("__label__conservative", "They wouldn't be that worried about the unprofitable criminal enterprises because they wouldn't last very long."),
    ("__label__conservative", "They ship millions of dollars of drugs into the United States."),
    ("__label__conservative", "Because when someone is over the retirement age , it's rather hard to see how many years you would add on projecting how long that person would continue to work beyond the age of retirement eligibility."),
    ("__label__liberal", "It is hard to see that , just in the sense of laundering , nothing is being concealed."),
    ("__label__liberal", "They're not the money that's being paid to the runners and the collectors , it is an ordinary and necessary expense of the illegal business."),
    ("__label__liberal", "So I think Justice Scalia was emphasizing that this is , for the very same conduct two discrete statutes , one with much heavier penalties."),
    ("__label__liberal", "That makes it odd , too , that the basic gambling statute has a lower penalty than this money laundering statute , and yet it's the same conduct that's violating both."),
    ("__label__liberal", "And it seems to me that he was narrowing his definition of proceeds to cases where the crime is not robbery or a one-time event , but a business-like operation."),
    ("__label__liberal", "If this Court should say that that theory , that it's profits and not proceeds that matter , wouldn't it be appropriate for us , if we don't decide the question ourselves , to remand and say , Seventh Circuit , your precedent was wrong ; but you could consider a question that was not necessary for you to reach because you had your precedent on the profits issue."),
    ("__label__liberal", "And this is vastly disproportionate."),
    ("__label__liberal", "So what would be the sentence under the statute as it now exists."),
    ("__label__liberal", "May i just go back to a statement you made."),
    ("__label__liberal", "Would that be unconstitutional."),
    ("__label__liberal", "It is my educated prediction that he will do it again."),
    ("__label__liberal", "You have already acknowledged that the wealthy candidate can spend."),
    ("__label__liberal", "I don't think I could give a verdict to take someone's life."),
    ("__label__liberal", "I hate the death penalty."),
    ("__label__liberal", "He's entitled to a fair trial without prejudice."),
    ("__label__liberal", "But if they're going to think beyond what the briefs tell them , they ought to think of it for both sides , and not just for one side."),
    ("__label__liberal", "Now I'll say that I think is the discrimination of which he is complaining."),
    ("__label__liberal", "Treat us alike."),
    ("__label__liberal", "You could rewrite the plan and say when a person becomes disabled you get retirement , right at that moment."),
    ("__label__liberal", "Though it's a bit mean."),
    ("__label__liberal", "I think it takes disabled people and cuts their benefits with no benefit."),
    ("__label__liberal", "All they're trying to do is to help people who are disabled at a time when they are younger and probably have fairly good expenses , and everybody gets this kind of insurance."),
    ("__label__liberal", "No , because what you are looking at is to see whether the purpose of Congress is somehow implicated , a purpose designed to prevent stereotypical thinking from being used to put older people at a disadvantage."),
    ("__label__liberal", "You said the reason is we treat them all like we treat them when you retire."),
    ("__label__liberal", "But if I could have them somehow together , I could look at the least evil way or the most efficient way of achieving the congressional objective."),
]

# Create and open the training file and write all the data we inputed to this
with open("train_labels.txt", "w") as file:
    for label, text in data:
      #use LLM to determine how to write a tuple set into the file instead of just one string
        file.write(f"{label} {text}\n")

#import downloaded before
import fasttext
#want to train model for 100 epochs: refer to hw3 for more explanation
model = fasttext.train_supervised('train_labels.txt', epoch=100, lr=1.5,  # Adjust learning rate
    wordNgrams=3)
#used LLM to get lr and wordNgrams since accuracies were low and asked for approach to make them higher

model.save_model("train_labels.bin")

model.test('train_labels.txt')

sentences = [
    "old people should receive pension benefits when they retire",
    "drugs are a huge issue in America",
    "i don't believe the death penalty is humane",
    "racism is a fundemental issue",
    "police officers should be treated with respect",
]

# want to predict what the labels are for the sentences we provided it with
for line in sentences:
    result_label = model.predict(line)
    print(f"Sentence: {line}")
    print(f"Label: {result_label}\n")

#want to use classifier like hw4 to find labels for ambigious sentences and compare with the fasttext model
#use LLM for this section:
!pip install transformers datasets torch

#used LLM for this section:

from transformers import pipeline

classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

# the two labels we are using
labels = ["liberal", "conservative"]


#the setences are not from LLM rather from .cha files from 2007
#chose sentences from different justices that were ambigious

sentences = [
    #06/10119
    "I thought your objection was with respect to the death penalty.",
    #06/1037
    "It doesn't say that you can't discriminate on the basis of age,so you can't prefer the older person over the younger person.",
    #06/1005
    "They can be guilty of illegal gambling without being guilty of money laundering",
    #06/1037
    "He has six years to go to qualify for retirement , so let him retire",
    #06/1005
    "And Congress there's no reason that Congress would have considered those professional money launderers to be less culpable merely because they might be laundering only illicit receipts",
    #06/1005
    "they may have enormous gross revenue, but they may have they may have enormous expenses overseas",
]


for sentence in sentences:
    result = classifier(sentence, candidate_labels=labels)
    print("Sentence:", sentence)
    print("Predicted Label:", result["labels"][0], "Score:", result["scores"][0])
    print()